#!/usr/bin/env python3
# Copyright 2023 The Lynx Authors. All rights reserved.
# Licensed under the Apache License Version 2.0 that can be found in the
# LICENSE file in the root directory of this source tree.



"""
usage: gn_to_podspec.py [-h] --json-path JSON_PATH --start-target START_TARGET --sub-target SUB_TARGET --compiler-target COMPILER_TARGET --podspec-path PODSPEC_PATH
                        [--keep-subspecs KEEP_SUBSPECS [KEEP_SUBSPECS ...]]
Use 'python gn_to_podspec.py -h' to get more help.

A project.json file should be generated by gn before using this script!!!

The command of 'gn gen OUTPUT_PATH --ide=json' will generate the project.json file. 
This json file contain compile flags, link flags, dependencies, defines and so on. 
This script will convert the content of project.json to a podspec file.

If you just want to convert gn to Lynx.podspec, LynxDevtool.podspec, XElement.podspec or LynxService.podspec, 
Please use 'tools/ios_tools/generate_ios_podspec_by_gn.py' directly.
"""

import argparse
import json
import logging
import os
import posixpath
import sys

SPEC_HEAD_LENGTH = 25

class Project:
  def __init__(self, project_json, start_target, sub_target, compiler_target, output_name):
    self.targets = project_json['targets']
    self.build_settings = project_json['build_settings']
    self.root_path = self.build_settings['root_path']
    self.build_path = posixpath.join(self.root_path,
                                     self.build_settings['build_dir'][2:])
    self.start_target = start_target
    self.compiler_target = compiler_target
    self.sub_target = sub_target
    self.output_name = output_name

  def get_absolute_path(self, path):
    if path.startswith("//"):
      return self.root_path + "/" + path[2:]
    return path
  
  def find_all_dependencies(self, main_target):
    """
    Find all of main_target's dependencies based on the dependency tree
    """
    all_targets = {}
    all_targets[main_target.gn_name] = main_target
    r = self.find_dependent_targets(main_target, main_target, all_targets)
    targets_list = []
    for key in all_targets.keys():
      targets_list.append(all_targets[key])
    targets_list.sort(key=lambda t: t.gn_name)
    return targets_list
  
  def find_dependent_targets(self, main_target, cur_target, all_targets):
    """
    Recursive lookup dependencies
    """
    if not cur_target.gn_name in self.targets.keys():
      logging.info('Can not find target %s' % (cur_target.gn_name))
      return -1
    all_targets[cur_target.gn_name] = cur_target
    deps = cur_target.properties.get('deps', [])
    if deps == []:
      return 0
    else:
      for dep in deps:
        dep_target = Target(dep, self)
        r = self.find_dependent_targets(main_target, dep_target, all_targets)
        if r != 0:
          return r
      return 0
    
class Target:
  """
  The object corresponding to the gn target
  """
  def __init__(self, gn_target_name, project):
    self.gn_name = gn_target_name
    self.properties = project.targets[self.gn_name]
    self.gn_type = self.properties.get('type', None)

class Writer:
  """
  Format content and then write formatted content to .podspec file
  """
  def __init__(self, project, output_path):
    output_name = project.output_name
    file_name = output_name
    path = posixpath.join(output_path, file_name)
    self.out = open(path, 'w+')

  def write_header(self):
    self.out.write('# Copyright 2019 The Lynx Authors. All rights reserved.\n')
    self.out.write('# coding: utf-8\n')

  def write_global_variables(self, global_variables):
    if global_variables == None or len(global_variables) == 0:
      self.out.write('\n')
      return
    self.out.write('\n')
    for variable in global_variables:
      self.out.write(variable)
      self.out.write('\n')
    self.out.write('\n')

  def write_base_info(self, base_info_lines):
    if base_info_lines == None:
      return
    for line in base_info_lines:
      self.out.write(line)
    self.out.write('\n')

  def write_list_content(self, key, value, header, space):
    list_value = ''
    for v in value:
      list_value += '\"%s\", ' % (v)
    list_value = list_value[:len(list_value)-2]
    full_str = self.format_head_str(key, header, space) + ' = %s \n' %(list_value)
    self.out.write(full_str)
  
  def format_head_str(self, key, header, space):
    head_str = '%s%s.%s' % (space, header, key)
    head_str = head_str.ljust(SPEC_HEAD_LENGTH + len(space), ' ')
    return head_str
  
  def write_condition(self, condition, space):
    self.out.write('\n')
    self.out.write(space + 'if ' + condition)

  def write_subspec_title(self, header, sub_header, space, spec_name, testonly):
    self.out.write('\n')
    if testonly:
      self.out.write('%s%s.test_spec \"%s\" do |%s|\n' % (space, header, spec_name, sub_header))
    else:
      self.out.write('%s%s.subspec \"%s\" do |%s|\n' % (space, header, spec_name, sub_header))

  def write_file_list(self, sources, header, space, title):
    space_len = SPEC_HEAD_LENGTH + len(space)
    i = 0
    has_value = False
    for source in sources:
      if source == '*':
        continue
      has_value = True
      if source.startswith("//"):
        source = source[2:]
      full_str = ''
      if i == 0:
        title_str = '%s%s.%s' % (space, header, title)
        t_len = SPEC_HEAD_LENGTH - len(header) - len(title) - 1
        length = t_len + len(title_str)
        title_str = title_str.ljust(length, ' ')
        full_str = title_str + ' = \"%s\"' % (source)
        if len(sources) == 1:
          full_str += '\n'
        else:
          full_str += ',\n'
      else:
        if i == len(sources) - 1:
          full_str = '\"%s\"\n' % (source)
        else:
          full_str = '\"%s\",\n' % (source)
        length = space_len + len(full_str) + 3
        full_str = full_str.rjust(length, ' ')
      self.out.write(full_str)
      i += 1
    if has_value:
      self.out.write('\n')

  def write_compiler_flags(self, flags, header, space):
    if len(flags) == 0:
      return
    self.write_list_content('compiler_flags', flags, header, space)

  def write_frameworks(self, frameworks, header, space):
    if len(frameworks) == 0:
      return
    format_frameworks = []
    for f in frameworks:
      format_frameworks.append(f[:-10])
    self.write_list_content('framework', format_frameworks, header, space)

  def write_header_property(self, value, header, space, property_name):
    if value == None:
      return
    value = '\"%s\"' % value
    full_str = self.format_head_str(property_name, header, space) + ' = ' + value + '\n'
    self.out.write(full_str)

  def write_libraries(self, libraries, header, space):
    if len(libraries) == 0:
      return
    self.write_list_content('libraries', libraries, header, space)

  def write_vender_libraries(self, vender_libraries,header, space):
    if len(vender_libraries) == 0:
      return
    self.write_file_list(vender_libraries, header, space, 'vendored_libraries')

  def write_original_lines(self, lines):
    if lines == None:
      return
    self.out.write('\n')
    for line in lines:
      if line.strip() == 'end':
        continue
      self.out.write(line)

  def write_source_file(self, sources, header, space):
    self.write_file_list(sources, header, space, 'source_files')

  def write_exclude_files(self, exclude_files, header, space):
    if len(exclude_files) == 0:
      return
    self.write_file_list(exclude_files, header, space, 'exclude_files')

  def write_public_headers(self, public_headers, spec_header, space):
    self.write_file_list(public_headers, spec_header, space, 'public_header_files')

  def write_private_headers(self, private_headers, spec_header, space):
    self.write_file_list(private_headers, spec_header, space, 'private_header_files')

  def write_xc_configs(self, configs, header, space):
    if len(configs.keys()) == 0:
      return
    space_len = SPEC_HEAD_LENGTH + len(space)
    title_str = '%s%s.pod_target_xcconfig ' % (space, header)
    title_str = title_str.ljust(2 + len(title_str), ' ')
    self.out.write(title_str)
    self.out.write(' = {\n')
    i = 0
    for key in configs.keys():
      if key == 'defines':
        k = 'GCC_PREPROCESSOR_DEFINITIONS'
        v = configs[key]
        if len(v) > 3:
          self.write_defines_item(k, v, space, ' \\', False, len(title_str)+4)
        else:
          self.write_defines_item(k, v, space, ' ', True, 0)
      elif key == 'include_dirs':
        k = 'HEADER_SEARCH_PATHS'
        self.write_search_path_item(k, configs[key], space, ' \\', len(title_str)+4)
      elif key == 'cflags_cc':
        k = 'CLANG_CXX_LANGUAGE_STANDARD'
        self.write_defines_item(k, configs[key], space, ' ', True, 0)
      if i == len(configs.keys())-1:
        self.out.write('\n')
      else:
        self.out.write(',\n')
      i += 1
      
    end_str = '}\n'
    end_str = end_str.rjust(space_len + len(end_str)+3, ' ')
    self.out.write(end_str)
    self.out.write('\n')

  def write_defines_item(self, key, value, space, sep, is_single_line, parent_len):
    space_len = SPEC_HEAD_LENGTH + len(space)
    full_str = '\"%s\" => ' % (key)
    value_str = '\"'
    for v in value:
      append_str = '%s%s' % (v, sep)
      if not is_single_line:
        append_str += '\n'
        append_str = append_str.ljust(len(key)+4+len(append_str)+parent_len, ' ')
      value_str += append_str
    sep_len = len(sep) if is_single_line else len(sep)+parent_len+len(key)+5
    value_str = value_str[:-sep_len]
    full_str += value_str + '\"'
    full_str = full_str.rjust(len(full_str) + space_len + 5, ' ')
    self.out.write(full_str)

  def write_search_path_item(self, key, value, space, sep, parent_len):
    space_len = SPEC_HEAD_LENGTH + len(space)
    full_str = '\"%s\" => ' % (key)
    value_str = '\"'
    for v in value:
      append_str = '\\\"%s\\\"%s' % (v, sep)
      append_str += '\n'
      append_str = append_str.ljust(len(key)+4+len(append_str)+parent_len, ' ')
      value_str += append_str
    sep_len = len(sep)+parent_len+len(key)+5
    value_str = value_str[:-sep_len]
    value_str += '\"'
    full_str += value_str
    full_str = full_str.rjust(len(full_str) + space_len + 5, ' ')
    self.out.write(full_str)
  
  def write_dependencies(self, dependencies, header, space):
    if len(dependencies) == 0:
      return
    for dep in dependencies:
      dep_str_list = dep.split(',')
      full_str = self.format_head_str('dependency', header, space) + '   '
      for s in dep_str_list:
        full_str += ('\"%s\"' % (s)) + ', '
      full_str = full_str[:-2]
      full_str += '\n'
      self.out.write(full_str)
  
  def write_scheme(self, header, space):
    self.out.write(self.format_head_str('scheme', header, space) + ' = ')
    self.out.write('{ :code_coverage => true }')
    self.out.write('\n')

  def write_bundle_data(self, sources, bundle_name, header, space):
    if len(sources) == 0:
      return
    head_str = self.format_head_str('resource_bundles', header, space) + ' = {\n'
    self.out.write(head_str)
    key_str = '\"%s\" => [' % (bundle_name)
    key_str = key_str.rjust(len(key_str) + len(space)+2)
    self.out.write(key_str)
    self.out.write('\n')
    value_str = ''
    for source in sources:
      if source.startswith('//'):
        source = source[2:]
      append_str = '\"%s\",' % (source)
      append_str = append_str.rjust(len(key_str)+len(append_str), ' ')
      value_str += append_str + '\n'
    value_str = value_str[:-2]
    self.out.write(value_str)
    self.out.write('\n')
    self.out.write('%s  ]\n' % space)
    self.out.write('%s}\n' % (space))

  def write_end(self, space):
    self.out.write('%send\n' % space)

# GN has no syntax for private headers. So we calculate private headers based on public headers
# If the header sources is not in public headers list, we add it to private headers list
def get_private_headers(sources, public_headers, testonly):
  public_paths = set()
  for header in public_headers:
    path = os.path.dirname(header)
    public_paths.add(path)
  private_paths = set()
  private_headers = []
  for source in sources:
    if not (source.endswith('.h') or source.endswith('.hpp')):
      continue
    if source in public_headers:
      continue
    path = os.path.dirname(source)
    file_names = os.path.basename(source).split('.')
    file_name = file_names[0]
    if path in public_paths:
      private_headers.append(source)
    else:
      if testonly:
        if file_name.endswith('UnitTestUtils'):
          name_suf = file_name[-13:]
          suf = '/*%s.{h,hpp}' % (name_suf)
          full_path = path + suf
        elif file_name.lower().endswith('unittest'):
          name_suf = file_name[-8:]
          suf = '/*%s.{h,hpp}' % (name_suf)
          full_path = path + suf
        else:
          full_path = path + '/*.{h,hpp}'
      else:
        full_path = path + '/*.{h,hpp}'
      private_paths.add(full_path)
  private_headers.extend(private_paths)
  private_headers.sort()
  return private_headers

def strip_base_flags(flags, base_flags):
  result = []
  tmp = {}
  for flag in flags:
    has_scan = tmp.get(flag, False)
    if flag in base_flags and not has_scan:
      tmp[flag] = True
      continue
    result.append(flag)
  return result

def strip_compiler_flags(flags, first_compiler_flags):
  # Flags defined in target are added to the front of the list
  # and flags added through configs are added to the backend of the list
  if type(flags) != list or first_compiler_flags == 'None':
    return
  idx = flags.index(first_compiler_flags)
  return flags[:idx]

def merge_compiler_flags(target, base_target):
  base_cflags = base_target.properties.get('cflags', ['None'])
  base_cflags_objc = base_target.properties.get('cflags_objc', ['None'])
  base_cflags_objcc = base_target.properties.get('cflags_objcc', ['None'])
  base_cflags_c = base_target.properties.get('cflags_c', ['None'])
  base_cflags_cc = base_target.properties.get('cflags_cc', ['None'])
  cflags = target.properties.get('cflags', [])
  cflags = strip_compiler_flags(cflags, base_cflags[0])
  cflags_objc = target.properties.get('cflags_objc', [])
  cflags_objc = strip_compiler_flags(cflags_objc, base_cflags_objc[0])
  cflags_objcc = target.properties.get('cflags_objcc', [])
  cflags_objcc = strip_compiler_flags(cflags_objcc, base_cflags_objcc[0])
  cflags_c = target.properties.get('cflags_c', [])
  cflags_c = strip_compiler_flags(cflags_c, base_cflags_c[0])
  cflags_cc = target.properties.get('cflags_cc', [])
  cflags_cc = strip_compiler_flags(cflags_cc, base_cflags_cc[0])

  result = []
  if cflags != None:
    result.extend(cflags)
  if cflags_c != None:
    result.extend(cflags_c)
  if cflags_cc != None:
    result.extend(cflags_cc)
  if cflags_objc != None:
    result.extend(cflags_objc)
  if cflags_objcc != None:
    result.extend(cflags_objcc)

  return result

def format_includes(include_dirs):
  format_includes = []
  for include in include_dirs:
    dir = ''
    if include.startswith('//PODS'):
      dir = include.replace('//PODS', '${PODS_ROOT}')
    elif include.startswith('//BUILD'):
      dir = include.replace('//BUILD', '${TARGET_BUILD_DIR}')
    elif include.startswith('//ROOT'):
      dir = include.replace('//ROOT', '${PODS_TARGET_SRCROOT}')
    else:
      dir = include.replace('//', '${PODS_TARGET_SRCROOT}/')
    format_includes.append(dir)
  format_includes.sort()
  return format_includes

def get_sub_target_deps(target_deps, project, full_deps_names):
  all_deps = {}
  for t_key in target_deps.keys():
    t = target_deps[t_key]
    all_deps[t_key] = t
    tmp_deps = project.find_all_dependencies(t)
    for d in tmp_deps:
      # Filter other subspec deps
      if d.gn_name in full_deps_names:
        continue
      all_deps[d.gn_name] = d
  targets_list = []
  for key in all_deps.keys():
    targets_list.append(all_deps[key])
  targets_list.sort(key=lambda t: t.gn_name)
  return targets_list

def get_all_libs(target, project, compiler_target):
  # Only the libs contained by the target that is directly dependent are taken
  deps = target.properties.get('deps', [])
  cur_libs = target.properties.get('libs', [])
  result = []
  if len(deps) == 0:
    compiler_libs = compiler_target.properties.get('libs', [])
    result = strip_base_flags(cur_libs, compiler_libs)
  else:
    deps_libs = set()
    for d in deps:
      t = Target(d, project)
      deps_libs.update(get_dependent_content(t, project, compiler_target, 'libs'))
    result = strip_base_flags(cur_libs, deps_libs)
  return result

def get_dependent_content(target, project, compiler_target, key):
  all_targets = project.find_all_dependencies(target)
  all_targets.remove(target)
  result_set = set()
  if len(all_targets) == 0:
    all_targets.append(compiler_target)
  for t in all_targets:
    r = set(t.properties.get(key, []))
    result_set.update(r)
  return result_set

def get_public_headers(target):
  result_set = set()
  public = target.properties.get('public', None)
  if type(public) == str and public == '*':
    # Handle wildcards
    sources = target.properties.get('sources', [])
    for source in sources:
      if source.endswith('.h') or source.endswith('.hpp'):
        result_set.add(source)
  else:
    result_set = set(public)
  return result_set

def write_subspec(project,
                 script_targets,
                 compiler_target,
                 start_target,
                 sub_target,
                 writer,
                 keep_subspecs_dict,
                 ):
  header = 's'
  sub_header = 'sp'
  space = '  '
  main_deps = start_target.properties.get('deps', [])
  subspec_list = set(sub_target.properties.get('deps', []))
  spec_name = start_target.gn_name.split(':')[-1]

  all_deps = project.find_all_dependencies(start_target)
  full_deps_names = set()
  for t in all_deps:
    full_deps_names.add(t.gn_name)
  r = 0
  for dep in main_deps:
    cur_target = Target(dep, project)
    r |= write_single_subspec(project,
                              spec_name,
                              script_targets,
                              full_deps_names,
                              compiler_target,
                              cur_target,
                              subspec_list,
                              keep_subspecs_dict,
                              writer,
                              header,
                              sub_header, 
                              space)
  return r

def write_single_subspec(project,
                         parent_name,
                         script_targets,
                         full_deps_names,
                         compiler_target,
                         cur_target,
                         subspec_list,
                         keep_subspecs_dict,
                         writer, 
                         header, 
                         sub_header, 
                         space):
  """
  Use arguments to assemble a complete subspec.
  This method will recursively convert the gn target to subspec.
  """
  if type(writer) != Writer:
    return -1
  deps_targets = cur_target.properties.get('deps', [])
  metadata = cur_target.properties.get('metadata', [])
  suffix_list = set(metadata.get('suffix_list', []))
  if cur_target.gn_type in ['source_set', 'static_library']:
    sources = []
    subspec_deps = []
    target_deps = {}
    for name in deps_targets:
      target = Target(name, project)
      is_self = name == cur_target.gn_name
      is_sub = name in subspec_list
      if is_sub and not is_self:
        subspec_deps.append(target)
      else:
        target_deps[name] = target

    spec_name = cur_target.gn_name.split(':')[1]
    last = spec_name.split('_')[-1]
    parent = spec_name[:-(len(last)+1)]
    if parent_name == parent:
      spec_name = last

    targets_list = get_sub_target_deps(target_deps, project, full_deps_names)
    current_sources = cur_target.properties.get('sources', [])
    for target in targets_list:
      if target.gn_type in ['loadable_module', 'shared_library', 'static_library', 'source_set']:
        s = target.properties.get('sources', [])
        sources.extend(s)
    if len(suffix_list) > 0:
      tmp = []
      for source in sources:
        ex = os.path.splitext(source)[-1]
        if ex in suffix_list:
          tmp.append(source)
      sources = tmp
    sources.extend(current_sources)
    sources.sort()

    bf = get_dependent_content(cur_target, project, compiler_target, 'frameworks')
    defines = cur_target.properties.get('defines', [])
    compiler_defines = compiler_target.properties.get('defines', ['None'])
    defines = list(set(defines) - set(compiler_defines))
    frameworks = cur_target.properties.get('frameworks', [])
    frameworks = strip_base_flags(frameworks, bf)
    compiler_include_dirs = compiler_target.properties.get('include_dirs', ['None'])
    include_dirs = cur_target.properties.get('include_dirs', [])
    include_dirs = strip_base_flags(include_dirs, compiler_include_dirs)
    cflags_cc = cur_target.properties.get('cflags_cc', [])
    libs = get_all_libs(cur_target, project, compiler_target)
    base_public = get_dependent_content(cur_target, project, compiler_target, 'public')
    current_public = get_public_headers(cur_target)
    testonly = cur_target.properties.get('testonly', [])
    condition_deps_list = metadata.get('condition_deps', [])
    dependencies = metadata.get('dependencies', [])
    ios_dependencies = metadata.get('ios_dependencies', [])
    header_mappings_dir_list = metadata.get('header_mappings_dir', [])
    header_dir_list = metadata.get('header_dir', [])
    exclude_files_list = metadata.get('exclude_files', [])
    scripts = script_targets.get(spec_name, None)

    header_mappings_dir = None
    if len(header_mappings_dir_list):
      header_mappings_dir = header_mappings_dir_list[0]
    header_dir = None
    if len(header_dir_list):
      header_dir = header_dir_list[0]

    condition_deps = None
    if len(condition_deps_list) > 0:
      condition_deps = condition_deps_list[0]

    sources_set = set(sources)
    public_set = sources_set.intersection(base_public)
    public_set = public_set.union(set(current_public))
    public_set = public_set.difference({'*'})
    public_headers = list(public_set)
    public_headers.sort()
    private_headers = get_private_headers(sources, public_headers, testonly)
    
    # Handle escape characters
    format_defines = []
    for define in defines:
      dl = define.split('"')
      ds = ''
      for s in dl:
        ds += s+'\\\"'
      ds = ds[:-2]
      format_defines.append(ds)

    format_cflags_cc = []
    for flag in cflags_cc:
      if flag == '-std=c++17':
        format_cflags_cc.append("c++17")

    configs = {}
    if len(format_defines) > 0:
      configs['defines'] = format_defines
    if len(include_dirs):
      configs['include_dirs'] = format_includes(include_dirs)
    if len(cflags_cc):
      configs['cflags_cc'] = format_cflags_cc

    # Libraries that specifies an absolute path is treated as vender libraries
    libraries = []
    vender_libraries = []
    for lib in libs:
      if lib.startswith('//'):
        lib = lib[2:]
        vender_libraries.append(lib)
      else:
        libraries.append(lib)

    compiler_flags = merge_compiler_flags(cur_target, compiler_target)
    
    if testonly:
      sub_header = 'test_spec'
    
    header_space = space + '  '
    condition_space = space
    if condition_deps != None:
      space += ' '
      header_space += '  '
      writer.write_condition(condition_deps, condition_space)

    keep_target = keep_subspecs_dict.get(spec_name, None)
    if keep_target != None:
      writer.write_original_lines(keep_target)
    else:
      writer.write_subspec_title(header, sub_header, space, spec_name, testonly)
      writer.write_compiler_flags(compiler_flags, sub_header, header_space)
      writer.write_frameworks(frameworks, sub_header, header_space)
      writer.write_header_property(header_mappings_dir, sub_header, header_space, 'header_mappings_dir')
      writer.write_header_property(header_dir, sub_header, header_space, 'header_dir')
      writer.write_libraries(libraries,  sub_header, header_space)
      writer.write_vender_libraries(vender_libraries,  sub_header, header_space)
      writer.write_original_lines(scripts)
      writer.write_public_headers(public_headers, sub_header, header_space)
      writer.write_private_headers(private_headers, sub_header, header_space)
      writer.write_source_file(sources, sub_header, header_space)
      writer.write_exclude_files(exclude_files_list, sub_header, header_space)
      writer.write_xc_configs(configs, sub_header, header_space)
      writer.write_dependencies(dependencies, sub_header, header_space)
      writer.write_dependencies(ios_dependencies, sub_header + '.ios', header_space)
      if testonly:
        writer.write_scheme(sub_header, header_space)

    for target in subspec_deps:
      write_single_subspec(project,
                           spec_name,
                           script_targets,
                           full_deps_names,
                           compiler_target, 
                           target,
                           subspec_list,
                           keep_subspecs_dict,
                           writer, 
                           sub_header, 
                           's'+sub_header, 
                           header_space)
      
    writer.write_end(space)
    if condition_deps != None:
      writer.write_end(condition_space)
  elif cur_target.gn_type == 'bundle_data':
    # bundle_data will be converted to resource_bundles
    sources = cur_target.properties.get('sources', [])
    bundle_name = cur_target.gn_name.split(':')[1]
    writer.write_bundle_data(sources, bundle_name, header, space)
  return 0

def write_podspec(project, base_info_lines, script_dict, keep_subspecs_dict):
  output_path = posixpath.join(project.build_path, 'podspecs')
  if not os.path.exists(output_path):
    os.makedirs(output_path)
  writer = Writer(project, output_path)

  compiler_target = Target(project.compiler_target, project)
  main_target = Target(project.start_target, project)
  sub_target = Target(project.sub_target, project)
  metadata = main_target.properties.get('metadata', [])
  global_variables = metadata.get('global_variables', [])

  writer.write_header()
  writer.write_global_variables(global_variables)
  writer.write_base_info(base_info_lines)
  r = write_subspec(project, script_dict, compiler_target, main_target, sub_target, writer, keep_subspecs_dict)
  writer.write_end('')
  writer.out.write('\n')
  return r

def read_original_script(subspec_dict, script_subspec_dict):
  script_dict = {}
  for name in script_subspec_dict.keys():
    script_lines = []
    subspec = subspec_dict.get(name, [])
    fs = False
    fp = False
    if subspec == None or len(subspec) == 0:
      continue
    title_line = subspec[0]
    sub_headers = title_line.split('|')
    sub_header = ''
    if len(sub_headers) > 2:
      sub_header = sub_headers[-2]
    for line in subspec:
      strip_line = line.strip()
      if 'script_phases' in line:
        script_lines.append(line)
        fs = True
        if fp == True:
          fp = False
      elif 'preserve_paths' in line:
        script_lines.append(line)
        fp = True
        if fs == True:
          fs = False
      elif fs:
        if strip_line.startswith(sub_header):
          fs = False
        else:
          script_lines.append(line)
      elif fp:
        if strip_line.startswith(sub_header):
          fp = False
        else:
          script_lines.append(line)
    script_dict[name] = script_lines
  return script_dict

def get_subspec_name(line):
  strip_line = line.strip()
  line_list = strip_line.split(' ')
  if len(line_list) > 1:
    name = line_list[1]
    name = name.strip('"')
    name = name.strip('\'')
    return name
  else:
    return ''

# We read base info such as homepage,license from original podspec file
# and write these info to generated podspec file
def read_original_podspec_info(podspec_path):
  base_info_lines = []
  subspec_dict = {}
  script_subspec_dict = {}
  podspec_file = open(podspec_path)
  line = podspec_file.readline()
  while line:
    strip_line = line.strip()
    if '.subspec' in line or '.test_spec' in line:
      name = get_subspec_name(line)
      subspec_lines = []
      subspec_lines.append(line)
      subspec_dict[name] = subspec_lines
      read_subspec(podspec_file, subspec_dict, script_subspec_dict, name)
      line = podspec_file.readline()
    elif strip_line.startswith('#') or strip_line.startswith('$'):
      line = podspec_file.readline()
      continue
    elif strip_line.startswith('if $'):
      read_condition(podspec_file, subspec_dict, script_subspec_dict)
      line = podspec_file.readline()
    else:
      if strip_line != 'end' and strip_line != '':
        base_info_lines.append(line)
      line = podspec_file.readline()
  return base_info_lines, subspec_dict, script_subspec_dict

def read_condition(file, subspec_dict, script_subspec_dict):
  line = file.readline()
  while line:
    strip_line = line.strip()
    if '.subspec' in line or '.test_spec' in line:
      sub_name = get_subspec_name(line)
      ss_lines = []
      ss_lines.append(line)
      subspec_dict[sub_name] = ss_lines
      read_subspec(file, subspec_dict, script_subspec_dict, sub_name)
      line = file.readline()
    elif strip_line.startswith('if $'):
      read_condition(file, subspec_dict, script_subspec_dict)
      line = file.readline()
    elif strip_line == 'end':
      break
    else:
      line = file.readline()
        
def read_subspec(file, subspec_dict, script_subspec_dict, name):
  line = file.readline()
  subspec_lines = subspec_dict[name]
  while line:
    strip_line = line.strip()
    if '.subspec' in line or '.test_spec' in line:
      sub_name = get_subspec_name(line)
      ss_lines = []
      ss_lines.append(line)
      subspec_dict[sub_name] = ss_lines
      read_subspec(file, subspec_dict, script_subspec_dict, sub_name)
      line = file.readline()
    elif strip_line.startswith('if $'):
      read_condition(file, subspec_dict, script_subspec_dict)
      line = file.readline()
    elif strip_line == 'end':
      subspec_lines.append(line)
      break
    elif strip_line.startswith('#'):
      line = file.readline()
      continue
    else:
      if 'script_phases' in line:
        script_subspec_dict[name] = True
      subspec_lines.append(line)
      line = file.readline()
      continue
  subspec_dict[name] = subspec_lines

def gn_to_podspec(json_path, start_target, sub_target, compiler_target, podspec_path, keep_subspecs):
  dir_name, file_name = os.path.split(podspec_path)
  project_json = None
  with open(json_path, 'r') as json_file:
    project_json = json.loads(json_file.read())
  project = Project(project_json, start_target, sub_target, compiler_target, file_name)
  base_info_lines, subspec_dict, script_subspec_dict = read_original_podspec_info(podspec_path)
  script_dict = read_original_script(subspec_dict, script_subspec_dict)
  keep_subspecs_dict = {}
  for name in keep_subspecs:
    s = subspec_dict.get(name, [])
    keep_subspecs_dict[name] = s
  return write_podspec(project, base_info_lines, script_dict, keep_subspecs_dict)

def main():
  parser = argparse.ArgumentParser()
  parser.add_argument('--json-path', type=str, required=True, help='GN target json file path.')
  parser.add_argument('--start-target', type=str, required=True, help='The target from which you want to generate podspec')
  parser.add_argument('--sub-target', type=str, required=True, help='The group target that contains all grade II and above subspec')
  parser.add_argument('--compiler-target', type=str, required=True, help='The target from which you want to get basic compiler flags')
  parser.add_argument('--podspec-path', type=str, required=True, help='The podspec path you want to generate and override')
  parser.add_argument('--keep-subspecs', nargs='+', required=False, help='The subspec that reads the content from the original file')
  args = parser.parse_args()
  json_path = args.json_path
  start_target = args.start_target
  sub_target = args.sub_target
  compiler_target = args.compiler_target
  podspec_path = args.podspec_path
  keep_subspecs = args.keep_subspecs
  if keep_subspecs == None:
    keep_subspecs = []

  return gn_to_podspec(json_path, start_target, sub_target, compiler_target, podspec_path, keep_subspecs)

if __name__ == "__main__":
  sys.exit(main())